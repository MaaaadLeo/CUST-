import cv2
import mediapipe as mp
import math
import numpy as np
import os
import random  # ã€æ–°å¢ã€‘ç”¨äºç”Ÿæˆéšæœºç²’å­
from PIL import Image, ImageDraw, ImageFont


# ================= 0. æ™ºèƒ½å­—ä½“åŠ è½½å™¨ (ä¿æŒä¸å˜) =================
def load_chinese_font(size=40):
    """
    ä¼˜å…ˆåŠ è½½é¡¹ç›®ç›®å½•ä¸‹çš„ simhei.TTFï¼Œå¦‚æœæ²¡æœ‰ï¼Œå†å»æ‰¾ç³»ç»Ÿå­—ä½“
    """
    candidate_paths = [
        "simhei.TTF",
        "simhei.ttf",
        "SimHei.ttf",
        "/System/Library/Fonts/PingFang.ttc",
        "/System/Library/Fonts/Heiti SC.ttc",
        "/System/Library/Fonts/Supplemental/Songti.ttc"
    ]
    selected_font = None
    for path in candidate_paths:
        if os.path.exists(path):
            try:
                selected_font = ImageFont.truetype(path, size)
                print(f"âœ… æˆåŠŸåŠ è½½å­—ä½“: {path}")
                break
            except Exception as e:
                continue
    if selected_font is None:
        print("âŒ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        selected_font = ImageFont.load_default()
    return selected_font


# ================= ã€æ–°å¢ã€‘ç²’å­åŠ¨ç”»ç±»å®šä¹‰ =================
class HeartParticle:
    def __init__(self, x, y):
        """åˆå§‹åŒ–ä¸€ä¸ªç²’å­"""
        self.x = x
        self.y = y
        # éšæœºé€Ÿåº¦ï¼šè®©ç²’å­å‘å››é¢å…«æ–¹ç‚¸å¼€
        self.vx = random.uniform(-8, 8)
        self.vy = random.uniform(-8, 8)
        # åˆå§‹å¤§å°å’Œç”Ÿé•¿é€Ÿåº¦
        self.size = random.randint(5, 15)
        self.grow_speed = random.uniform(0.5, 1.5)
        # å¯¿å‘½ï¼šç²’å­èƒ½å­˜æ´»å¤šå°‘å¸§
        self.life = random.randint(20, 40)
        # é¢œè‰²ï¼šå¸¦é€æ˜åº¦çš„ç²‰è‰² (R, G, B, Alphaé€æ˜åº¦)
        self.color = (255, 105, 180, random.randint(150, 220))

    def update(self):
        """æ¯ä¸€å¸§æ›´æ–°ç²’å­çš„çŠ¶æ€"""
        self.x += self.vx
        self.y += self.vy
        self.size += self.grow_speed
        self.life -= 1

    def is_alive(self):
        """æ£€æŸ¥ç²’å­æ˜¯å¦è¿˜æ´»ç€"""
        return self.life > 0


# ================= 1. åˆå§‹åŒ–æ¨¡å‹å’Œå…¨å±€å˜é‡ =================
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=2)
mp_draw = mp.solutions.drawing_utils
TIP_IDS = [4, 8, 12, 16, 20]

# ã€æ–°å¢å…¨å±€å˜é‡ã€‘
particles = []  # å­˜å‚¨æ´»è·ƒç²’å­çš„åˆ—è¡¨
gesture_was_active = False  # è®°å½•ä¸Šä¸€å¸§æ˜¯å¦è§¦å‘äº†çˆ±å¿ƒï¼Œé˜²æ­¢é‡å¤è§¦å‘

# ã€ä¼˜åŒ–ã€‘é¢„å…ˆåŠ è½½å¤§å·å­—ä½“ï¼Œé¿å…åœ¨åŠ¨ç”»å¾ªç¯ä¸­é‡å¤åŠ è½½å¯¼è‡´å¡é¡¿
main_font = load_chinese_font(size=80)


# ================= 2. è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) =================
def calculate_distance(p1, p2):
    return math.hypot(p1.x - p2.x, p1.y - p2.y)


def get_finger_status(hand_landmarks, hand_label):
    fingers = []
    # å¤§æ‹‡æŒ‡
    if hand_label == 'Left':
        if hand_landmarks.landmark[4].x < hand_landmarks.landmark[3].x:
            fingers.append(1)
        else:
            fingers.append(0)
    else:
        if hand_landmarks.landmark[4].x > hand_landmarks.landmark[3].x:
            fingers.append(1)
        else:
            fingers.append(0)
    # å…¶ä»–å››æŒ‡
    for id in range(1, 5):
        if hand_landmarks.landmark[TIP_IDS[id]].y < hand_landmarks.landmark[TIP_IDS[id] - 2].y:
            fingers.append(1)
        else:
            fingers.append(0)
    return fingers


# ================= 3. ä¸»ç¨‹åº =================
cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)

print("ğŸš€ ç©¶æèåˆç‰ˆç³»ç»Ÿå¯åŠ¨ä¸­... å‡†å¤‡æ¯”å¿ƒï¼")

while True:
    success, img = cap.read()
    if not success: break

    img = cv2.flip(img, 1)
    h, w, _ = img.shape
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    face_results = face_mesh.process(img_rgb)
    hand_results = hands.process(img_rgb)

    final_message = ""
    # æ³¨æ„ï¼šä¸ºäº†é…åˆ PIL çš„ RGBA ç»˜å›¾ï¼Œè¿™é‡Œé¢œè‰²ä½¿ç”¨ RGB æ ¼å¼
    message_color = (255, 255, 255)
    gesture_detected = False

    # ã€æ–°å¢ã€‘å½“å‰å¸§çš„çˆ±å¿ƒçŠ¶æ€æ ‡è®°å’Œä¸­å¿ƒç‚¹
    is_loving_now = False
    love_center = (w // 2, h // 2)

    # ----------------- æ‰‹åŠ¿è¯†åˆ« -----------------
    if hand_results.multi_hand_landmarks:
        # çˆ±å¿ƒæ£€æµ‹
        if len(hand_results.multi_hand_landmarks) == 2:
            hand1 = hand_results.multi_hand_landmarks[0]
            hand2 = hand_results.multi_hand_landmarks[1]
            # æ£€æŸ¥é£ŸæŒ‡å°–è·ç¦»
            if calculate_distance(hand1.landmark[8], hand2.landmark[8]) < 0.1:
                final_message = "çˆ±ä½ æ â¤ï¸"
                message_color = (255, 105, 180)  # ç²‰è‰² RGB
                gesture_detected = True

                # ã€æ–°å¢ã€‘æ ‡è®°å½“å‰ä¸ºçˆ±å¿ƒçŠ¶æ€ï¼Œå¹¶è®¡ç®—çˆ†ç‚¸ä¸­å¿ƒç‚¹ï¼ˆä¸¤é£ŸæŒ‡ä¸­é—´ï¼‰
                is_loving_now = True
                cx = int((hand1.landmark[8].x + hand2.landmark[8].x) / 2 * w)
                cy = int((hand1.landmark[8].y + hand2.landmark[8].y) / 2 * h)
                love_center = (cx, cy)

        # å•æ‰‹æ£€æµ‹ (ä¿ç•™ä½ çš„åŸå§‹é€»è¾‘)
        if not gesture_detected:
            for hand_landmarks, hand_info in zip(hand_results.multi_hand_landmarks, hand_results.multi_handedness):
                hand_label = hand_info.classification[0].label
                fingers = get_finger_status(hand_landmarks, hand_label)
                thumb_tip_y = hand_landmarks.landmark[4].y
                thumb_ip_y = hand_landmarks.landmark[3].y

                if fingers[1] == 0 and fingers[2] == 1 and fingers[3] == 0 and fingers[4] == 0:
                    final_message = "ä½ å‚»é€¼å—"
                    message_color = (255, 0, 0)  # çº¢è‰² RGB
                    gesture_detected = True
                elif fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 0 and fingers[4] == 0:
                    final_message = "è€¶âœŒï¸"
                    message_color = (255, 255, 0)  # é»„è‰² RGB
                    gesture_detected = True
                elif fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:
                    if thumb_tip_y < thumb_ip_y:
                        final_message = "å¤ªå¸¦æ´¾äº†ï¼"
                        message_color = (255, 165, 0)  # æ©™è‰² RGB
                        gesture_detected = True
                    elif thumb_tip_y > thumb_ip_y:
                        final_message = "å¤ªé€Šäº†"
                        message_color = (128, 128, 128)  # ç°è‰² RGB
                        gesture_detected = True
                elif fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 1:
                    final_message = "ä¹Ÿå°±è¿™æ ·å§"
                    message_color = (100, 100, 100)  # æ·±ç° RGB
                    gesture_detected = True

                mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # ----------------- è¡¨æƒ…è¯†åˆ« (ä¿ç•™åŸå§‹é€»è¾‘) -----------------
    if not gesture_detected and face_results.multi_face_landmarks:
        for face_landmarks in face_results.multi_face_landmarks:
            left_y = face_landmarks.landmark[61].y * h
            right_y = face_landmarks.landmark[291].y * h
            lips_y = (face_landmarks.landmark[13].y * h + face_landmarks.landmark[14].y * h) / 2
            offset = lips_y - (left_y + right_y) / 2
            if offset > 8:
                final_message = "å¼€å¿ƒ :)"
                message_color = (0, 255, 0)  # ç»¿è‰² RGB
            elif offset < -8:
                final_message = "éš¾è¿‡ :("
                message_color = (0, 0, 255)  # è“è‰² RGB

    # ================= ã€æ ¸å¿ƒä¿®æ”¹ã€‘åŠ¨ç”»è§¦å‘ä¸æ¸²æŸ“ =================

    # 1. ç²’å­è§¦å‘é€»è¾‘ï¼šå¦‚æœå½“å‰æ˜¯çˆ±å¿ƒï¼Œä¸”ä¸Šä¸€å¸§ä¸æ˜¯ï¼Œåˆ™è§¦å‘çˆ†ç‚¸
    if is_loving_now and not gesture_was_active:
        for _ in range(60):  # ç”Ÿæˆ60ä¸ªç²’å­
            particles.append(HeartParticle(love_center[0], love_center[1]))

    # æ›´æ–°çŠ¶æ€ï¼Œä¾›ä¸‹ä¸€å¸§åˆ¤æ–­
    gesture_was_active = is_loving_now

    # 2. å¼€å§‹æ¸²æŸ“ï¼šå°† OpenCV å›¾åƒè½¬æ¢ä¸º PIL RGBA æ¨¡å¼ (å¸¦é€æ˜é€šé“)
    pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)).convert("RGBA")

    # 3. åˆ›å»ºä¸€ä¸ªå®Œå…¨é€æ˜çš„å›¾å±‚ï¼Œç”¨äºç»˜åˆ¶ç²’å­å’Œæ–‡å­—
    overlay = Image.new('RGBA', pil_img.size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(overlay)

    # 4. æ›´æ–°å¹¶ç»˜åˆ¶æ‰€æœ‰æ´»è·ƒç²’å­åˆ°é€æ˜å±‚ä¸Š
    alive_particles = []
    for p in particles:
        p.update()
        if p.is_alive():
            # ç”»åŠé€æ˜åœ†å½¢
            draw.ellipse(
                [p.x - p.size, p.y - p.size, p.x + p.size, p.y + p.size],
                fill=p.color, outline=None
            )
            alive_particles.append(p)
    particles = alive_particles  # æ¸…ç†æ­»æ‰çš„ç²’å­

    # 5. ç»˜åˆ¶æ–‡å­—åˆ°é€æ˜å±‚ä¸Š (ä½¿ç”¨é¢„åŠ è½½çš„å¤§å·å­—ä½“)
    if final_message:
        # å°† RGB é¢œè‰²è½¬æ¢ä¸º RGBA (å®Œå…¨ä¸é€æ˜)
        text_color_rgba = (message_color[0], message_color[1], message_color[2], 255)
        draw.text((50, 100), final_message, font=main_font, fill=text_color_rgba)

    # 6. å›¾å±‚åˆæˆï¼šå°†é€æ˜å±‚å åŠ åˆ°è§†é¢‘èƒŒæ™¯å±‚ä¸Š
    # alpha_composite æ˜¯å®ç°é«˜è´¨é‡åŠé€æ˜å åŠ çš„å…³é”®
    pil_img = Image.alpha_composite(pil_img, overlay)

    # 7. è½¬å› OpenCV æ ¼å¼ç”¨äºæ˜¾ç¤º
    img_final = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGBA2BGR)

    cv2.imshow('Ultimate Gesture FX', img_final)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()